{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_search(query, api_key, cse_id, **kwargs):\n",
    "    url = \"https://www.googleapis.com/customsearch/v1\"\n",
    "    params = {\n",
    "        'q': query,\n",
    "        'key': api_key,\n",
    "        'cx': cse_id\n",
    "    }\n",
    "    params.update(kwargs)\n",
    "    response = requests.get(url, params=params)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your API key and Programmable Search Engine ID\n",
    "api_key = 'AIzaSyCAV73EKedKhVm3Vslz389wY6_OB1z2aw0'\n",
    "cse_id = '74a9c6ca4ecd7403c'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract the date from the snippet\n",
    "def extract_date(snippet):\n",
    "    # Regular expression pattern to match dates in the format: \"MMM dd, yyyy\" or \"yyyy\"\n",
    "    date_pattern = re.compile(r'\\b(?:Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|Apr(?:il)?|May|Jun(?:e)?|Jul(?:y)?|Aug(?:ust)?|Sep(?:tember)?|Oct(?:ober)?|Nov(?:ember)?|Dec(?:ember)?|\\d{4}) \\d{1,2}, \\d{4}|\\d{4}')\n",
    "    match = date_pattern.search(snippet)\n",
    "    return match.group(0) if match else \"Date not found\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract date from snippet using regex\n",
    "def extract_date(snippet):\n",
    "    # Regex pattern for various date formats\n",
    "    date_pattern = re.compile(r'\\b(?:\\d{1,2} (?:Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|Apr(?:il)?|May|Jun(?:e)?|Jul(?:y)?|Aug(?:ust)?|Sep(?:tember)?|Oct(?:ober)?|Nov(?:ember)?|Dec(?:ember)?) \\d{4}|'  # dd MMM yyyy\n",
    "                               r'(?:Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|Apr(?:il)?|May|Jun(?:e)?|Jul(?:y)?|Aug(?:ust)?|Sep(?:tember)?|Oct(?:ober)?|Nov(?:ember)?|Dec(?:ember)?) \\d{1,2} \\d{4}|'  # MMM dd yyyy\n",
    "                               r'\\b(?:Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|Apr(?:il)?|May|Jun(?:e)?|Jul(?:y)?|Aug(?:ust)?|Sep(?:tember)?|Oct(?:ober)?|Nov(?:ember)?|Dec(?:ember)?|\\d{4}) \\d{1,2}, \\d{4}|'  # MMM dd, yyyy\n",
    "                               r'\\d{4})')  # yyyy\n",
    "    match = date_pattern.search(snippet)\n",
    "    return match.group(0) if match else \"Date not found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract the publisher from the URL\n",
    "def extract_publisher(url):\n",
    "    domain = urlparse(url).netloc\n",
    "    # Remove 'www.' prefix if it exists\n",
    "    if domain.startswith('www.'):\n",
    "        domain = domain[4:]\n",
    "    # Extract publisher name before the first dot\n",
    "    publisher = domain.split('.')[0]\n",
    "    return publisher.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_query = 'AI job market in 2024'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example search\n",
    "results = google_search(search_query, api_key, cse_id, num=4, siteSearch='youtube.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: I Spent 8 Weeks Researching the 2024 Tech Job Market - YouTube\n",
      "Link: https://www.youtube.com/watch?v=Q8uFrhdrr00\n",
      "Thumbnail: https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQVXsP-UbZ_LdlGTcT0lR3ctjMS9NvYkBpe6_TRuyvBwT6NeEpvn1sZw6lA&s\n",
      "--------------------------------------------------------------------------------\n",
      "Title: Exploring Job Market Of Generative AI Engineers- Must Skillset ...\n",
      "Link: https://www.youtube.com/watch?v=BvI5qxMxHSU\n",
      "Thumbnail: https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSGSPhz7Ky4GLZhWxog0DZYyLiJS7f_Q9HIm1ggozA-wb8m1XRcSKdVdPV8&s\n",
      "--------------------------------------------------------------------------------\n",
      "Title: I Spent 8 Hours Researching the 2024 Coding Job Market - YouTube\n",
      "Link: https://www.youtube.com/watch?v=s-dSXx9EwZE\n",
      "Thumbnail: https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQ2KKUXqoknnPbwgqwbE5yW-KeNsVPTikdxJhLl699_VbJGS_wPQ5FvKlw&s\n",
      "--------------------------------------------------------------------------------\n",
      "Title: How AI Will Impact the 2024 Job Market - YouTube\n",
      "Link: https://www.youtube.com/watch?v=ujVhJggHmos\n",
      "Thumbnail: https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRcl6uGIKa-LazjWrSJMhvsjCjm8jpCx2dgAGuUyks0pLfoeDeqGUeVz3A&s\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Process and print the results\n",
    "for item in results.get('items', []):\n",
    "    print(f\"Title: {item['title']}\")\n",
    "    print(f\"Link: {item['link']}\")\n",
    "    print(f\"Thumbnail: {item.get('pagemap', {}).get('cse_thumbnail', [{}])[0].get('src')}\")\n",
    "    print('-' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: $10,000 Every Day You Survive In The Wilderness - YouTube\n",
      "Link: https://www.youtube.com/watch?v=U_LlX4t0A9I\n",
      "Date: Jun 1, 2024\n",
      "Publisher: Youtube\n",
      "--------------------------------------------------------------------------------\n",
      "Title: MrBeast on X: \"Just filmed our biggest video ever.. https://t.co ...\n",
      "Link: https://twitter.com/MrBeast/status/1798465522008252438\n",
      "Date: Jun 5, 2024\n",
      "Publisher: Twitter\n",
      "--------------------------------------------------------------------------------\n",
      "Title: Protect The Yacht, Keep It! - YouTube\n",
      "Link: https://www.youtube.com/watch?v=F6PqxbvOCUI&vl=en\n",
      "Date: May 11, 2024\n",
      "Publisher: Youtube\n",
      "--------------------------------------------------------------------------------\n",
      "Title: The new MrBeast video is kind of a sad reality check. :/ : r/MrBeast\n",
      "Link: https://www.reddit.com/r/MrBeast/comments/1c8w8j4/the_new_mrbeast_video_is_kind_of_a_sad_reality/\n",
      "Date: Apr 20, 2024\n",
      "Publisher: Reddit\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Process and print the results\n",
    "for item in results.get('items', []):\n",
    "    title = item.get('title', 'No title')\n",
    "    snippet = item.get('snippet', 'No snippet')\n",
    "    link = item.get('link', 'No link')\n",
    "    \n",
    "    # Extract the date from the snippet\n",
    "    date = extract_date(snippet)\n",
    "    publisher = extract_publisher(link)\n",
    "    \n",
    "    print(f\"Title: {title}\")\n",
    "    print(f\"Link: {link}\")\n",
    "    print(f\"Date: {date}\")\n",
    "    print(f\"Publisher: {publisher}\")\n",
    "    print('-' * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
